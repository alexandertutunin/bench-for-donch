{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "sys.path.append(os.path.abspath(os.path.join(os.getcwd(), '..')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "torch.manual_seed(1488)\n",
    "\n",
    "from utils import DatasetWindowed, StructuredBCELoss\n",
    "from utils import make_distant_old\n",
    "from utils import train_epoch, test_epoch\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from dataset import dataset\n",
    "from monitoring import Monitor\n",
    "\n",
    "import cpuinfo\n",
    "\n",
    "\n",
    "start_idx = 80*20\n",
    "scaling = 14.88"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train, labels_train = dataset.load(train=True)\n",
    "data_train = make_distant_old(data_train, scaling=scaling)\n",
    "train_embs = DatasetWindowed(data_train, labels_train, wsize=320, stride=1, start_idx=start_idx, device=\"cuda\")\n",
    "\n",
    "print(f\"Embeddings are on   device={train_embs.all_windows.device}\")\n",
    "print(f\"emb-Labels are on   device={train_embs.all_labels.device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_test, labels_test = dataset.load(train=False)\n",
    "data_test = make_distant_old(data_test, scaling=scaling)\n",
    "test_embs = DatasetWindowed(data_test, labels_test, wsize=320, stride=1, start_idx=start_idx, device=\"cuda\")\n",
    "\n",
    "print(f\"Embeddings are on   device={test_embs.all_windows.device}\")\n",
    "print(f\"emb-Labels are on   device={test_embs.all_labels.device}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loader_train = DataLoader(train_embs, batch_size=32, shuffle=False)\n",
    "batch = next(iter(loader_train))\n",
    "batch_data, batch_target = batch\n",
    "print('Train Batch')\n",
    "print(f\"Batch-data are on       device={batch_data.device}\")\n",
    "print(f\"Batch-Labels are on     device={batch_target.device}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loader_test = DataLoader(test_embs, batch_size=32, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from models import MaxMapRNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\")\n",
    "\n",
    "if device == torch.device(\"cpu\"):\n",
    "    device_desc = f\"{cpuinfo.get_cpu_info()['brand_raw']}| {os.cpu_count()} threads\"\n",
    "    print(device_desc)\n",
    "elif device == torch.device(\"cuda\"):\n",
    "    device_desc = torch.cuda.get_device_name(device)\n",
    "    print(device_desc)\n",
    "\n",
    "model = MaxMapRNN(kernel_size=4, input_size=320, hidden_size=128, rnn_layers=3).to(device)\n",
    "print(model)\n",
    "print(f\"Num of params: {sum(p.numel() for p in model.parameters())}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import Timer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "monitor = Monitor()\n",
    "timer = Timer(timing='s')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 10\n",
    "learning_rate = 0.0025\n",
    "betas = (0.607, 0.999)\n",
    "\n",
    "model.to(device)\n",
    "\n",
    "criterion = StructuredBCELoss(pos_weight=14.88, reg_sharpness=0.00, reg_nonfaulty=0.00)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate, betas=betas)\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=8, gamma=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "train_score = None\n",
    "timer.tick(\"train\")\n",
    "for epoch in range(num_epochs):\n",
    "    \n",
    "    print(\"-\"*50)\n",
    "    score_str = f\"{train_score*100:.3f}\" if train_score else \"||\"\n",
    "\n",
    "    print(f\"Epoch [{epoch+1}/{num_epochs}] | Score: {score_str}%\")\n",
    "\n",
    "\n",
    "    train_loss, train_score, train_components, grad_norms, clipped_grad_norms = train_epoch(model,\n",
    "                                                                        loader_train,\n",
    "                                                                        criterion,\n",
    "                                                                        optimizer,\n",
    "                                                                        scheduler=scheduler,\n",
    "                                                                        grad_clipping=None)\n",
    "    \n",
    "    monitor.add_train_loss(train_loss)\n",
    "    monitor.add_named_loss_components(train_components, source=\"train\")\n",
    "    \n",
    "    test_loss, test_score, test_components = test_epoch(model, loader_test, criterion)\n",
    "    monitor.add_test_loss(test_loss)\n",
    "    monitor.add_named_loss_components(train_components, source=\"test\")\n",
    "    monitor.add_gradnorms(grad_norms)\n",
    "    monitor.add_clipped_gradnorms(clipped_grad_norms)\n",
    "    \n",
    "    names = [x[0] for x in model.named_parameters()]\n",
    "\n",
    "    monitor.show()\n",
    "    monitor.plot_gradnorms_by_param(names)\n",
    "    monitor.plot_clipped_gradnorms_by_param(names)\n",
    "\n",
    "timer.tuck(\"train\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iter_per_sec = num_epochs / (timer.show()['train [s]']).item()\n",
    "\n",
    "sec_per_iter = 1/iter_per_sec\n",
    "\n",
    "print(f\"Total Performance: \\n   {iter_per_sec:.5f} epoch/s\\n   {sec_per_iter:.5f} s/epoch\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "filename = \"./performance.json\"\n",
    "\n",
    "# Step 1: Load existing data or create new list\n",
    "if os.path.exists(filename):\n",
    "    try:\n",
    "        with open(filename, \"r\") as f:\n",
    "            f_json = json.load(f)\n",
    "    except json.JSONDecodeError:\n",
    "        f_json = []  # file is empty or invalid JSON\n",
    "else:\n",
    "    f_json = []\n",
    "\n",
    "# Step 2: Append new record\n",
    "f_json.append({\n",
    "    \"device\": device_desc + \" (dataset on GPU)\",\n",
    "    \"ep/s\": iter_per_sec,\n",
    "    \"s/ep\": sec_per_iter,\n",
    "    \"total_epochs\": num_epochs\n",
    "})\n",
    "\n",
    "# Step 3: Write updated list back to file\n",
    "with open(filename, \"w\") as f:\n",
    "    json.dump(f_json, f, indent=4)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
